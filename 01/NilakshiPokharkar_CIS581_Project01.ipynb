{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nilakshi Pokharkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data i.e train.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.dat', delimiter=' ', names=['Year', 'Working_Age_Population'])\n",
    "train_year = df_train['Year'].to_numpy().reshape(-1,1)\n",
    "train_population = df_train['Working_Age_Population'].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data i.e test.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.dat', delimiter=' ', names=['Year', 'Working_Age_Population'])\n",
    "test_year = df_test['Year'].to_numpy().reshape(-1,1)\n",
    "test_population = df_test['Working_Age_Population'].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train, test data and split into features and target variable and also initialize KFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_year\n",
    "y = train_population\n",
    "\n",
    "X_test = test_year\n",
    "y_test = test_population\n",
    "\n",
    "kf = KFold(n_splits = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the arrays for degrees from 0 to 12(inclusive) and alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] \n",
    "\n",
    "e = math.e \n",
    "alphas = [0, e ** -25, e ** -20, e ** -14, e ** -7, e ** -3, 1, e ** 3, e **7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate StandardScaler object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the avg_rsme on each fold without lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "avg_rmse_list = []\n",
    "\n",
    "rmse_list_train = []\n",
    "avg_rmse_list_train = []\n",
    "for degree in degrees:\n",
    "    rmse_scores = []\n",
    "    avg_rmse = 0\n",
    "    \n",
    "    rmse_scores_train = []\n",
    "    avg_rmse_train = 0\n",
    "  \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # Split the data into training and Validation sets\n",
    "        X_train, X_Val = X[train_index], X[val_index]\n",
    "        y_train, y_Val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Using StandardScaler to Normalize data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_Val_scaled = scaler.transform(X_Val)\n",
    "        \n",
    "        y_train_scaled = scaler.transform(y_train)\n",
    "        y_Val_scaled = scaler.transform(y_Val)\n",
    "        \n",
    "        # polynomial features\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "        X_Val_poly = poly.transform(X_Val_scaled)\n",
    "        \n",
    "        # linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_poly, y_train_scaled)\n",
    "\n",
    "        # predictions on the Validation test set\n",
    "        y_pred_Val = model.predict(X_Val_poly)\n",
    "        y_pred_Val_inv = scaler.inverse_transform(y_pred_Val)\n",
    "        \n",
    "        # predictions on the Train set\n",
    "        y_pred_train = model.predict(X_train_poly)\n",
    "        y_pred_train_inv = scaler.inverse_transform(y_pred_train)\n",
    "\n",
    "        # To find the RMSE score \n",
    "        rmse = np.sqrt(mean_squared_error(y_Val, y_pred_Val_inv))\n",
    "        rmse_scores.append(rmse)\n",
    "        \n",
    "        rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train_inv))\n",
    "        rmse_scores_train.append(rmse_train)\n",
    "        \n",
    "        # Append the RMSE score to the average\n",
    "        avg_rmse += rmse\n",
    "        avg_rmse_train += rmse_train\n",
    "\n",
    "    #these are the errorson the Val set of the training data\n",
    "    avg_rmse /= kf.get_n_splits()\n",
    "    rmse_list.append(rmse_scores)\n",
    "    avg_rmse_list.append(avg_rmse)\n",
    "    \n",
    "    avg_rmse_train /= kf.get_n_splits()\n",
    "    rmse_list_train.append(rmse_scores_train)\n",
    "    avg_rmse_list_train.append(avg_rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the index of degree with the minimum avg_rsme.\n",
    "min(range(len(avg_rmse_list)), key=lambda x : avg_rmse_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))   \n",
    "plt.title(\"Graph 1: Avg RMSE vs.Degrees\", size=16)\n",
    "plt.scatter(degrees, avg_rmse_list)\n",
    "plt.plot(degrees, avg_rmse_list, c=\"red\", label='CV_test')\n",
    "plt.scatter(degrees, avg_rmse_list_train)\n",
    "plt.plot(degrees, avg_rmse_list_train, c=\"green\", label='CV_train')\n",
    "plt.ylabel(\"Avg. RMSE\")\n",
    "plt.xlabel(\"Degrees\")\n",
    "location = 0\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the avg_rsme on each fold with degree=12 and given array of alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "avg_rmse_list = []\n",
    "\n",
    "rmse_list_train = []\n",
    "avg_rmse_list_train = []\n",
    "for alpha in alphas:\n",
    "    rmse_scores = []\n",
    "    avg_rmse = 0\n",
    "    \n",
    "    rmse_scores_train = []\n",
    "    avg_rmse_train = 0\n",
    "  \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # Split the data into training and Validation sets\n",
    "        X_train, X_Val = X[train_index], X[val_index]\n",
    "        y_train, y_Val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Using StandardScaler to Normalize data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_Val_scaled = scaler.transform(X_Val)\n",
    "        \n",
    "        y_train_scaled = scaler.transform(y_train)\n",
    "        y_Val_scaled = scaler.transform(y_Val)\n",
    "        \n",
    "        # polynomial features\n",
    "        poly = PolynomialFeatures(degree=12)\n",
    "        X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "        X_Val_poly = poly.transform(X_Val_scaled)\n",
    "        \n",
    "        # Ridge model\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_train_poly, y_train_scaled)\n",
    "\n",
    "        #  predictions on the Validation test set\n",
    "        y_pred_Val = model.predict(X_Val_poly)\n",
    "        y_pred_Val_inv = scaler.inverse_transform(y_pred_Val)\n",
    "        \n",
    "        #  predictions on the Train set\n",
    "        y_pred_train = model.predict(X_train_poly)\n",
    "        y_pred_train_inv = scaler.inverse_transform(y_pred_train)\n",
    "\n",
    "        # To find the RMSE score \n",
    "        rmse = np.sqrt(mean_squared_error(y_Val, y_pred_Val_inv))\n",
    "        rmse_scores.append(rmse)\n",
    "        \n",
    "        rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train_inv))\n",
    "        rmse_scores_train.append(rmse_train)\n",
    "        \n",
    "        # Append the RMSE score to the average\n",
    "        avg_rmse += rmse\n",
    "        avg_rmse_train += rmse_train\n",
    "\n",
    "    #these are the errors on the Val set of the training data\n",
    "    avg_rmse /= kf.get_n_splits()\n",
    "    rmse_list.append(rmse_scores)\n",
    "    avg_rmse_list.append(avg_rmse)\n",
    "    \n",
    "    avg_rmse_train /= kf.get_n_splits()\n",
    "    rmse_list_train.append(rmse_scores_train)\n",
    "    avg_rmse_list_train.append(avg_rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))   \n",
    "plt.title(\"Graph 2: Avg RMSE vs. Alphas\", size=16)\n",
    "\n",
    "plt.scatter(alphas, avg_rmse_list)\n",
    "plt.plot(alphas, avg_rmse_list, c=\"red\", label='CV_test')\n",
    "\n",
    "plt.scatter(alphas, avg_rmse_list_train)\n",
    "plt.plot(alphas, avg_rmse_list_train, c=\"green\", label='CV_train')\n",
    "\n",
    "plt.ylabel(\"Avg. RMSE\")\n",
    "plt.xlabel(\"Alphas\")\n",
    "\n",
    "plt.xscale('log')\n",
    "\n",
    "location = 0\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the index of alpha with the minimum avg_rsme.\n",
    "min(range(len(avg_rmse_list)), key=lambda x : avg_rmse_list[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider d*=6 for training the model on train.dat and predit on train.dat & the plotting of Graph 3 and Calculation of the train RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the Input Feature and Target Variable\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "y_train_scaled = scaler.transform(y)\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=6)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "\n",
    "# Fit a linear regression model\n",
    "model_optD = LinearRegression(fit_intercept=True)\n",
    "model_optD.fit(X_train_poly, y_train_scaled)\n",
    "\n",
    "# predictions on the train.dat and test.dat set\n",
    "y_pred_train = model_optD.predict(X_train_poly)\n",
    "y_pred_train_inv = scaler.inverse_transform(y_pred_train)\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y, y_pred_train_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optD.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the test RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.dat set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "y_pred_test = model_optD.predict(X_test_poly)\n",
    "y_pred_test_inv = scaler.inverse_transform(y_pred_test)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,y_pred_test_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversions to plot the data \n",
    "train_dict = {}\n",
    "\n",
    "for i in range(df_train['Year'].shape[0]):\n",
    "    features = df_train['Year'][i]\n",
    "    output = y_pred_train_inv[i][0]\n",
    "    train_dict[features] = output\n",
    "    \n",
    "train_dict = dict(sorted(train_dict.items()))\n",
    "#print(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Graph 3 for best d(d*): Age population vs. Year)\", size=16)\n",
    "plt.scatter(X, y)\n",
    "plt.plot(np.array(list(train_dict.keys())), np.array(list(train_dict.values())), c=\"red\", label=\"Predicted Population on training data\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.xlabel(\"Years\")\n",
    "location = 0\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider λ*=e**3 and d=12 for training the model on train.dat and predit on train.dat & the plotting of Graph 4 and Calculation of the train RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the Input Feature and Target Variable\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "y_train_scaled = scaler.transform(y)\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=12)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "\n",
    "# Fit a Ridge model\n",
    "model_optL = Ridge(alpha=e**-3, fit_intercept=True)\n",
    "model_optL.fit(X_train_poly, y_train_scaled)\n",
    "\n",
    "# predictions on the test.dat set\n",
    "y_pred_train_l = model_optL.predict(X_train_poly)\n",
    "y_pred_train_inv_l = scaler.inverse_transform(y_pred_train_l)\n",
    "\n",
    "rmse_train_l = np.sqrt(mean_squared_error(y, y_pred_train_inv_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_optL.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the test RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.dat set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "y_pred_test_l = model_optL.predict(X_test_poly)\n",
    "y_pred_test_inv_l = scaler.inverse_transform(y_pred_test_l)\n",
    "\n",
    "rmse_test_l = np.sqrt(mean_squared_error(y_test, y_pred_test_inv_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversions to plot the data \n",
    "train_dict_l = {}\n",
    "\n",
    "for i in range(df_train['Year'].shape[0]):\n",
    "    features = df_train['Year'][i]\n",
    "    output = y_pred_train_inv[i][0]\n",
    "    train_dict_l[features] = output\n",
    "    \n",
    "train_dict_l = dict(sorted(train_dict_l.items()))\n",
    "#print(train_dict_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Graph 4 for best Lambda: Age population vs. Year)\", size=16)\n",
    "plt.scatter(X, y)\n",
    "\n",
    "plt.plot(np.array(list(train_dict_l.keys())), np.array(list(train_dict_l.values())), c=\"red\", label=\"Predicted Population on training data\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.xlabel(\"Years\")\n",
    "location = 0\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
